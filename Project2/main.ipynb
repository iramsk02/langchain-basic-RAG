{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78458966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "# HumanMessage: Represents the user.\n",
    "# AIMessage: Represents the model's response.\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "# ChatMessageHistory: A concrete, in-memory store for chat messages (user, AI, system).\n",
    "\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "# BaseChatMessageHistory: An abstract interface that defines how chat history should be stored and accessed.\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "# RunnableWithMessageHistory: A wrapper that adds automatic conversation memory to an LLM, chain, or agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af7252cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "model=ChatGroq(model=\"llama-3.3-70b-versatile\",groq_api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ec4dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Alena, it's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 42, 'total_tokens': 69, 'completion_time': 0.044296797, 'completion_tokens_details': None, 'prompt_time': 0.003729133, 'prompt_tokens_details': None, 'queue_time': 0.058379567, 'total_time': 0.04802593}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb2f3-ce2d-78b1-a0f3-ab4bedb3e1a5-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 42, 'output_tokens': 27, 'total_tokens': 69})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(input=[HumanMessage(content=\"Hello, My name is Alena\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de41005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't know your name. I'm a large language model, I don't have the ability to know your personal information or recall previous conversations. Each time you interact with me, it's a new conversation. If you'd like to share your name, I'd be happy to chat with you and address you by name.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 40, 'total_tokens': 107, 'completion_time': 0.145180518, 'completion_tokens_details': None, 'prompt_time': 0.001735718, 'prompt_tokens_details': None, 'queue_time': 0.064451182, 'total_time': 0.146916236}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c06d5113ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb2f4-4213-7b33-bf0d-053c2f3fab59-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 40, 'output_tokens': 67, 'total_tokens': 107})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(input=[HumanMessage(content=\"What is my name?\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09601824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Chris.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=[\n",
    "    \n",
    "  HumanMessage(content=\"Hi, [my name is Chris.\"),\n",
    "    AIMessage(content=\"Hello Chris! How can I help?\"),\n",
    "    HumanMessage(content=\"What is my name?\")]\n",
    "\n",
    "response=model.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08eb7292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Till now our model/chatbot is not able to mainatain a context or memory \n",
    "\n",
    "# A dictionary to keep track of sessions in memory\n",
    "store={}\n",
    "\n",
    "# This retrieves memory from story based on session Id\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "    \n",
    "#Lets add a wrapper which helps our model to use this memory\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    model,get_session_history\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2db7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Bob, and you're a web designer.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 109, 'total_tokens': 122, 'completion_time': 0.030384621, 'completion_tokens_details': None, 'prompt_time': 0.004915595, 'prompt_tokens_details': None, 'queue_time': 0.058944949, 'total_time': 0.035300216}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_68f543a7cc', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb2fd-b381-7ce2-8422-c41c6ed0183d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 109, 'output_tokens': 13, 'total_tokens': 122})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a config object that stores configuration of a session\n",
    "\n",
    "config1={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response1=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, I'm Bob and I'm a web designer\")],\n",
    "    config=config1\n",
    ")\n",
    "\n",
    "response1_0=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response1_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c68fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I still don\\'t know your name. You haven\\'t told me what it is. If you\\'d like to share your name with me, I\\'d be happy to learn it and use it in our conversation. Otherwise, I\\'ll just refer to you as \"you\" or \"user\".', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 115, 'total_tokens': 174, 'completion_time': 0.161490829, 'completion_tokens_details': None, 'prompt_time': 0.005108356, 'prompt_tokens_details': None, 'queue_time': 0.059679127, 'total_time': 0.166599185}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb2fe-70f1-7740-912a-65f0644b411f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 115, 'output_tokens': 59, 'total_tokens': 174})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "\n",
    "response2=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],\n",
    "    config=config2\n",
    ")\n",
    "# because we changed the configuration the llm can't remember name\n",
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaeca569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Your name is Harry.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 333, 'total_tokens': 339, 'completion_time': 0.006686497, 'completion_tokens_details': None, 'prompt_time': 0.10530212, 'prompt_tokens_details': None, 'queue_time': 0.162878869, 'total_time': 0.111988617}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_45180df409', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bb302-0165-7110-8ab1-ba7ecd8cf4d6-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 333, 'output_tokens': 6, 'total_tokens': 339}\n",
      "content='I don\\'t have any information about a \"Bob\" in our conversation so far. You\\'ve only introduced yourself as Harry, a businessman. I don\\'t know anything about a Bob. Would you like to tell me about Bob?' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 351, 'total_tokens': 398, 'completion_time': 0.100048983, 'completion_tokens_details': None, 'prompt_time': 0.022358271, 'prompt_tokens_details': None, 'queue_time': 0.071189469, 'total_time': 0.122407254}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_68f543a7cc', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bb302-02ae-7bc0-bd79-80ef9189eeef-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 351, 'output_tokens': 47, 'total_tokens': 398}\n"
     ]
    }
   ],
   "source": [
    "config3={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "\n",
    "with_message_history.invoke(\n",
    "     [HumanMessage(content=\"Hi, I'm Harry and I'm a Business man\")],\n",
    "    config=config3\n",
    ")\n",
    "response3=with_message_history.invoke(\n",
    "     [HumanMessage(content=\"what is my name\")],\n",
    "    config=config3\n",
    ")\n",
    "# now since chat 3 is different configuration our llm tells us about harry only\n",
    "print(response3)\n",
    "\n",
    "response3=with_message_history.invoke(\n",
    "     [HumanMessage(content=\"Who is Bob\")],\n",
    "    config=config3\n",
    ")\n",
    "print(response3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
