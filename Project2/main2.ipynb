{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d6454c",
   "metadata": {},
   "source": [
    "Integrating Chat Prompt Templates and Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4ce302",
   "metadata": {},
   "source": [
    "Prompt templates structure raw user input into a format suitable for the LLM, allowing for system instructions and specific message placeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dce2b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaee2583",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"ai\",\"You are a helpful assistant to guide user with their queries in {language}\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "489f1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "model=ChatGroq(model=\"llama-3.3-70b-versatile\",groq_api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c527ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e24ca50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "   chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7017764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Merhaba, iyiyim, sen nasılsın? (Hello, I'm fine, how are you?)\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 57, 'total_tokens': 82, 'completion_time': 0.088332987, 'completion_tokens_details': None, 'prompt_time': 0.002962855, 'prompt_tokens_details': None, 'queue_time': 0.064938645, 'total_time': 0.091295842}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_68f543a7cc', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb310-e170-7fc2-9507-b87155fa4731-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 57, 'output_tokens': 25, 'total_tokens': 82})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\":[HumanMessage(content=\"Hello how are you\")],\n",
    "        \"language\":\"Turkish\"\n",
    "    }\n",
    "    ,config=config1\n",
    ")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
